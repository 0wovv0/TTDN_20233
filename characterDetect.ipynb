{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OtsuThresholding(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        # Convert PIL Image or Tensor to NumPy array (if not already)\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            img = img.numpy().squeeze(0)  # Remove the channel dimension if grayscale\n",
    "            img = (img * 255).astype(np.uint8)  # Convert to uint8\n",
    "        \n",
    "        # Apply Otsu's Thresholding\n",
    "        _, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        \n",
    "        # Convert back to Tensor\n",
    "        img = torch.tensor(img, dtype=torch.float32).unsqueeze(0) / 255.0\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),  # Chuyển đổi sang ảnh xám trước khi áp dụng Otsu's Thresholding\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_image(path):\n",
    "    try:\n",
    "        img = Image.open(path)\n",
    "        img.verify()\n",
    "        return True\n",
    "    except (IOError, SyntaxError) as e:\n",
    "        print(f\"Bad file: {path}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(root='OCR\\\\gray_data\\\\training_data', transform=transform, is_valid_file=is_valid_image)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dataset = datasets.ImageFolder(root='OCR\\\\gray_data\\\\test_data', transform=transform, is_valid_file=is_valid_image)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataset = datasets.ImageFolder(root='OCR\\\\data2\\\\testing_data', transform=transform, is_valid_file=is_valid_image)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64*8*8, 128)\n",
    "        self.fc2 = nn.Linear(128, 36)  # 36 output classes (26 letters + 10 digits)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(nn.functional.max_pool2d(self.conv1(x), 2))\n",
    "        x = nn.functional.relu(nn.functional.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 64*8*8)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def trainModel(model):\n",
    "    num_epochs = 40\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)  # Chuyển images sang cùng thiết bị với model\n",
    "            labels = labels.to(device)  # Chuyển labels sang cùng thiết bị với model\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass và optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}')\n",
    "        torch.save(model.state_dict(), f'model_epoch_{epoch+1}.pth')\n",
    "        \n",
    "        # Đánh giá mô hình sau mỗi epoch\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        print(f'Validation Accuracy: {100 * correct / total} %')\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = SimpleCNN().to(device=device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40], Loss: 0.34074352481632686\n",
      "Validation Accuracy: 97.14285714285714 %\n",
      "Epoch [2/40], Loss: 0.0926566188913611\n",
      "Validation Accuracy: 99.18367346938776 %\n",
      "Epoch [3/40], Loss: 0.053430174961557095\n",
      "Validation Accuracy: 99.08163265306122 %\n",
      "Epoch [4/40], Loss: 0.032633934612761914\n",
      "Validation Accuracy: 99.79591836734694 %\n",
      "Epoch [5/40], Loss: 0.02051191053373987\n",
      "Validation Accuracy: 99.59183673469387 %\n",
      "Epoch [6/40], Loss: 0.018111307667878832\n",
      "Validation Accuracy: 99.59183673469387 %\n",
      "Epoch [7/40], Loss: 0.019380988547804432\n",
      "Validation Accuracy: 100.0 %\n",
      "Epoch [8/40], Loss: 0.01782402531026046\n",
      "Validation Accuracy: 99.79591836734694 %\n",
      "Epoch [9/40], Loss: 0.007359715120148611\n",
      "Validation Accuracy: 99.89795918367346 %\n",
      "Epoch [10/40], Loss: 0.01112286682637299\n",
      "Validation Accuracy: 99.89795918367346 %\n",
      "Epoch [11/40], Loss: 0.011418974068560695\n",
      "Validation Accuracy: 99.48979591836735 %\n",
      "Epoch [12/40], Loss: 0.010624879602793433\n",
      "Validation Accuracy: 100.0 %\n",
      "Epoch [13/40], Loss: 0.007246180464627398\n",
      "Validation Accuracy: 99.89795918367346 %\n",
      "Epoch [14/40], Loss: 0.004014581864286367\n",
      "Validation Accuracy: 100.0 %\n",
      "Epoch [15/40], Loss: 0.010128012455617385\n",
      "Validation Accuracy: 99.89795918367346 %\n",
      "Epoch [16/40], Loss: 0.008562766857364982\n",
      "Validation Accuracy: 100.0 %\n",
      "Epoch [17/40], Loss: 0.002368871145461998\n",
      "Validation Accuracy: 99.18367346938776 %\n",
      "Epoch [18/40], Loss: 0.00767958203451592\n",
      "Validation Accuracy: 99.89795918367346 %\n",
      "Epoch [19/40], Loss: 0.006202018867976282\n",
      "Validation Accuracy: 100.0 %\n",
      "Epoch [20/40], Loss: 0.0042675690654822036\n",
      "Validation Accuracy: 99.79591836734694 %\n",
      "Epoch [21/40], Loss: 0.0014499456072841002\n",
      "Validation Accuracy: 99.89795918367346 %\n",
      "Epoch [22/40], Loss: 0.008984518899984384\n",
      "Validation Accuracy: 100.0 %\n",
      "Epoch [23/40], Loss: 0.00754713221912211\n",
      "Validation Accuracy: 100.0 %\n",
      "Epoch [24/40], Loss: 0.0028414001994818525\n",
      "Validation Accuracy: 99.89795918367346 %\n",
      "Epoch [25/40], Loss: 0.0013737753944956417\n",
      "Validation Accuracy: 99.6938775510204 %\n",
      "Epoch [26/40], Loss: 0.007715233325068673\n",
      "Validation Accuracy: 100.0 %\n",
      "Epoch [27/40], Loss: 0.0030598967492517937\n",
      "Validation Accuracy: 100.0 %\n",
      "Epoch [28/40], Loss: 0.002315943520013263\n",
      "Validation Accuracy: 100.0 %\n",
      "Epoch [29/40], Loss: 0.00625282526648583\n",
      "Validation Accuracy: 100.0 %\n",
      "Epoch [30/40], Loss: 0.0016566566539586033\n",
      "Validation Accuracy: 100.0 %\n",
      "Epoch [31/40], Loss: 0.0029252586714610743\n",
      "Validation Accuracy: 99.89795918367346 %\n",
      "Epoch [32/40], Loss: 0.002961970601319458\n",
      "Validation Accuracy: 99.89795918367346 %\n",
      "Epoch [33/40], Loss: 0.0074018969195959305\n",
      "Validation Accuracy: 99.89795918367346 %\n",
      "Epoch [34/40], Loss: 0.0016782250674294225\n",
      "Validation Accuracy: 99.89795918367346 %\n",
      "Epoch [35/40], Loss: 7.765029927904385e-05\n",
      "Validation Accuracy: 100.0 %\n",
      "Epoch [36/40], Loss: 1.0754146334405011e-05\n",
      "Validation Accuracy: 100.0 %\n",
      "Epoch [37/40], Loss: 5.091494576576615e-06\n",
      "Validation Accuracy: 100.0 %\n",
      "Epoch [38/40], Loss: 3.5423118852818296e-06\n",
      "Validation Accuracy: 100.0 %\n",
      "Epoch [39/40], Loss: 2.5382487995267963e-06\n",
      "Validation Accuracy: 100.0 %\n",
      "Epoch [40/40], Loss: 1.8745738880786224e-06\n",
      "Validation Accuracy: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "trainModel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load lại model đã lưu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hokta\\AppData\\Local\\Temp\\ipykernel_9996\\2006280369.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('model_epoch_40.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleCNN().to('cuda')\n",
    "\n",
    "model.load_state_dict(torch.load('model_epoch_40.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet_and_digit = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.858592263792 %\n",
      "The accuracy: 3118 / 3154 \n",
      "\n",
      "\n",
      "Incorrect predictions:\n",
      "Predicted: I, Actual: 0\n",
      "Predicted: I, Actual: 0\n",
      "Predicted: I, Actual: 0\n",
      "Predicted: I, Actual: 0\n",
      "Predicted: 1, Actual: 2\n",
      "Predicted: I, Actual: A\n",
      "Predicted: 4, Actual: A\n",
      "Predicted: 3, Actual: B\n",
      "Predicted: 3, Actual: B\n",
      "Predicted: I, Actual: G\n",
      "Predicted: I, Actual: G\n",
      "Predicted: F, Actual: H\n",
      "Predicted: F, Actual: H\n",
      "Predicted: 1, Actual: J\n",
      "Predicted: I, Actual: J\n",
      "Predicted: I, Actual: J\n",
      "Predicted: I, Actual: J\n",
      "Predicted: I, Actual: J\n",
      "Predicted: 1, Actual: L\n",
      "Predicted: 1, Actual: L\n",
      "Predicted: V, Actual: M\n",
      "Predicted: V, Actual: M\n",
      "Predicted: 1, Actual: N\n",
      "Predicted: Y, Actual: N\n",
      "Predicted: R, Actual: P\n",
      "Predicted: P, Actual: R\n",
      "Predicted: P, Actual: R\n",
      "Predicted: H, Actual: R\n",
      "Predicted: 5, Actual: S\n",
      "Predicted: J, Actual: U\n",
      "Predicted: J, Actual: U\n",
      "Predicted: U, Actual: V\n",
      "Predicted: 1, Actual: X\n",
      "Predicted: 1, Actual: X\n",
      "Predicted: V, Actual: Y\n",
      "Predicted: I, Actual: Z\n"
     ]
    }
   ],
   "source": [
    "def testModel(model, test_loader, device):\n",
    "    model.eval()  # Đặt mô hình ở chế độ đánh giá\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    incorrect_predictions = []  # Danh sách lưu trữ các dự đoán sai\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Lưu trữ các dự đoán sai\n",
    "            for i in range(labels.size(0)):\n",
    "                if predicted[i] != labels[i]:\n",
    "                    incorrect_predictions.append((predicted[i].item(), labels[i].item()))\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {accuracy} %')\n",
    "\n",
    "    print(f'The accuracy: {correct} / {total} \\n')\n",
    "    # In ra các dự đoán sai\n",
    "    if incorrect_predictions:\n",
    "        print(\"\\nIncorrect predictions:\")\n",
    "        for pred, label in incorrect_predictions:\n",
    "            print(f\"Predicted: {alphabet_and_digit[pred]}, Actual: {alphabet_and_digit[label]}\")\n",
    "    else:\n",
    "        print(\"No incorrect predictions!\")\n",
    "\n",
    "# Gọi hàm testModel\n",
    "testModel(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path):\n",
    "    # Đảm bảo mô hình ở chế độ đánh giá\n",
    "    model.eval()\n",
    "    \n",
    "    # Đọc ảnh từ đường dẫn\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Áp dụng các phép biến đổi cho ảnh\n",
    "    image = transform(image).unsqueeze(0)  # Thêm batch dimension\n",
    "    \n",
    "    # Chuyển ảnh và mô hình sang thiết bị (CPU/GPU)\n",
    "    image = image.to(device)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Tiến hành dự đoán\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "    \n",
    "    # Chọn lớp có xác suất cao nhất\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    \n",
    "    # Chuyển đổi chỉ số dự đoán thành nhãn lớp\n",
    "    # Giả sử bạn có danh sách các lớp\n",
    "    classes =  [0, 1, 2, 3, 4,5, 6, 7, 8, 9, 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'\n",
    "]\n",
    "    predicted_class = classes[predicted.item()]\n",
    "    \n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc ảnh bằng PIL\n",
    "image = Image.open('plates.png')\n",
    "\n",
    "# Chuyển ảnh từ PIL sang NumPy array\n",
    "image_np = np.array(image)\n",
    "\n",
    "# Chuyển đổi ảnh màu (BGR) sang ảnh xám\n",
    "gray = cv2.cvtColor(image_np, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Hiển thị ảnh xám\n",
    "cv2.imshow('Gray Image', gray)\n",
    "\n",
    "# Đợi nhấn phím để đóng cửa sổ\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Đóng tất cả các cửa sổ\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_draw_contours():\n",
    "    # Đọc ảnh đã threshold (ảnh xám)\n",
    "    preprocessed_image = cv2.imread('thresholded_image.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "    original_image = cv2.imread('resized_image.jpg')\n",
    "\n",
    "    # Tìm các đường viền trên ảnh đã được threshold\n",
    "    contours, _ = cv2.findContours(preprocessed_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in contours:\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        \n",
    "        # Điều kiện lọc kích thước để loại bỏ các vùng không phải là đối tượng cần thiết\n",
    "        if h > 10 and w > 10:\n",
    "            # Vẽ hình chữ nhật xung quanh vùng đối tượng\n",
    "            cv2.rectangle(preprocessed_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Hiển thị ảnh với các đường viền\n",
    "    cv2.imshow(\"Contours\", preprocessed_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Gọi hàm để thực hiện phát hiện đường viền\n",
    "find_and_draw_contours()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def segment_objects(image_path):\n",
    "    # Đọc ảnh màu xám\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Áp dụng ngưỡng hóa\n",
    "    _, thresh = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Tạo kernel để thực hiện morphological operations\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "    # Áp dụng opening để loại bỏ nhiễu nhỏ\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "    # Dilation để chắc chắn rằng các đối tượng đã được tách biệt\n",
    "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
    "\n",
    "    # Distance Transform để tìm khoảng cách từ các điểm foreground\n",
    "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
    "    _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
    "\n",
    "    # Chuyển đổi foreground thành kiểu số nguyên\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "\n",
    "    # Tìm các vùng không chắc chắn\n",
    "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "\n",
    "    # Tạo markers cho thuật toán Watershed\n",
    "    _, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "    # Thêm 1 vào tất cả các markers để đảm bảo background là 1\n",
    "    markers = markers + 1\n",
    "\n",
    "    # Đặt vùng không chắc chắn là 0\n",
    "    markers[unknown == 0] = 0\n",
    "\n",
    "    # Áp dụng Watershed\n",
    "    original_image = cv2.imread(image_path)\n",
    "    markers = cv2.watershed(original_image, markers)\n",
    "\n",
    "    # Vẽ các đường viền tách biệt\n",
    "    original_image[markers == -1] = [0, 255, 0]\n",
    "\n",
    "    # Hiển thị ảnh kết quả\n",
    "    cv2.imshow(\"Segmented Objects\", original_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Gọi hàm với đường dẫn ảnh\n",
    "segment_objects('images\\\\test\\\\3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Đọc ảnh nhị phân\n",
    "image = cv2.imread('images\\\\test\\\\3.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Tạo kernel\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "# Erosion\n",
    "eroded_image = cv2.erode(image, kernel, iterations=1)\n",
    "\n",
    "# Dilation\n",
    "dilated_image = cv2.dilate(image, kernel, iterations=1)\n",
    "\n",
    "# Opening\n",
    "opening_image = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# Closing\n",
    "closing_image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Morphological Gradient\n",
    "gradient_image = cv2.morphologyEx(image, cv2.MORPH_GRADIENT, kernel)\n",
    "\n",
    "# Top Hat\n",
    "tophat_image = cv2.morphologyEx(image, cv2.MORPH_TOPHAT, kernel)\n",
    "\n",
    "# Black Hat\n",
    "blackhat_image = cv2.morphologyEx(image, cv2.MORPH_BLACKHAT, kernel)\n",
    "\n",
    "# Hiển thị kết quả\n",
    "cv2.imshow('Original', image)\n",
    "cv2.imshow('Eroded', eroded_image)\n",
    "cv2.imshow('Dilated', dilated_image)\n",
    "cv2.imshow('Opening', opening_image)\n",
    "cv2.imshow('Closing', closing_image)\n",
    "cv2.imshow('Gradient', gradient_image)\n",
    "cv2.imshow('Top Hat', tophat_image)\n",
    "cv2.imshow('Black Hat', blackhat_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Đọc ảnh và chuyển về ảnh xám\n",
    "image = cv2.imread('1.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Áp dụng thresholding để tạo ảnh nhị phân\n",
    "# _, binary_image = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY)\n",
    "_, binary_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# Sử dụng Connected Components\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary_image, connectivity=8)\n",
    "\n",
    "# Tạo ảnh màu để hiển thị các thành phần liên thông\n",
    "output_image = np.zeros((image.shape[0], image.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "# Gán màu ngẫu nhiên cho mỗi thành phần liên thông (trừ nền)\n",
    "for i in range(1, num_labels):\n",
    "    mask = labels == i\n",
    "    output_image[mask] = np.random.randint(0, 255, size=(3,), dtype=np.uint8)\n",
    "\n",
    "# Hiển thị kết quả\n",
    "cv2.imshow('Connected Components', output_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.imshow('original image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.imshow('Components', binary_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "\n",
    "def predict_image(image):\n",
    "    # Đọc ảnh\n",
    "    # image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "    # Tiền xử lý ảnh\n",
    "    input_tensor = transform(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Thêm chiều batch\n",
    "\n",
    "    # Kiểm tra xem có GPU không\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to('cuda')\n",
    "        model.to('cuda')\n",
    "\n",
    "    # Dự đoán\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)\n",
    "    \n",
    "    # Tinh toán xác suất và lớp dự đoán\n",
    "    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "    top_prob, top_class = torch.topk(probabilities, 1)\n",
    "    \n",
    "    # In kết quả\n",
    "    predicted_class = classes[top_class[0].item()]\n",
    "    predicted_prob = top_prob[0].item()\n",
    "    \n",
    "    print(f'Predicted class: {predicted_class}')\n",
    "    print(f'Probability: {predicted_prob:.4f}')\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: D\n",
      "Probability: 0.6855\n"
     ]
    }
   ],
   "source": [
    "predict_image('output\\\\bboxes\\\\bbox_2_label_U_conf_0.92.jpg')  # Thay đổi đường dẫn đến ảnh của bạn\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TTDN_20233",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
